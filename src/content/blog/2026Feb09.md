---
author: W
featured: false
draft: false
description: Dev weekly
pubDatetime: 2026-02-07T02:02:03Z
title: Dev weekly 2026-Feb-09
tags:
  - weekly
---

### AI

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?](https://arxiv.org/abs/2601.23045) from Anthropic 

[]()

[]()

[2026 Agentic Coding Trends Report](https://resources.anthropic.com/hubfs/2026%20Agentic%20Coding%20Trends%20Report.pdf?hsLang=en) by anthropic

[Unrolling the Codex agent loop](https://openai.com/index/unrolling-the-codex-agent-loop/)

[Evaluating Deep Agents: Our Learnings](https://blog.langchain.com/evaluating-deep-agents-our-learnings/) from langchain

[State of Agent Engineering](https://www.langchain.com/state-of-agent-engineering) by langchain

[姚顺雨在腾讯首个研究：在“上下文”这事上，在座的各位都不及格](https://mp.weixin.qq.com/s/3JFRCnDXYtrgrmCKJHl52w) Context Learning Benchmark https://arxiv.org/abs/2602.03587 结合后面提到的“AGENTS.md outperforms skills in our agent evals”一起看就有意思了

[How AI Impacts Skill Formation](https://arxiv.org/abs/2601.20245v1) 过分依赖人工智能完成不熟悉任务的新手工作者可能会在这个过程中牺牲自己的技能获取

[Radar Trends to Watch: January 2026](https://www.oreilly.com/radar/radar-trends-to-watch-january-2026/)


[]()


### Programming

[Claude Code / Codex / Gemini CLI 全方位辅助工具](https://github.com/farion1231/cc-switch/blob/main/README_ZH.md) *****

[AGENTS.md outperforms skills in our agent evals](https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals) **** 我们在注入的内容里加了一条关键指令。 "IMPORTANT: Prefer retrieval-led reasoning over pre-training-led reasoning 
for any Next.js tasks." 

[Vibe Engineering: What I've Learned Working with AI Coding Agents](https://mrexodia.substack.com/p/vibe-engineering-what-ive-learned)

[The Devdocs Methodology](https://github.com/mrexodia/devdocs-cli/blob/master/METHODOLOGY.md) design.md     # What we're building and why  ;  plan.md       # How we're building it, in phases

[Custom instructions with AGENTS.md](https://developers.openai.com/codex/guides/agents-md/) Codex reads AGENTS.md files before doing any work. By layering global guidance with project-specific overrides, you can start each task with consistent expectations, no matter which repository you open.

[Pi is a minimal terminal coding harness.](https://github.com/badlogic/pi-mono/tree/main/packages/coding-agent) Pi runs in four modes: interactive, print or JSON, RPC for process integration, and an SDK for embedding in your own apps. See openclaw/openclaw for a real-world SDK integration.

[The 2026 Guide to AI Agents
Your one-stop resource for gaining in-depth knowledge and hands-on applications of AI agents.](https://www.ibm.com/think/ai-agents)

[深度解析：Moltbot 底层架构](https://mp.weixin.qq.com/s/9ddNSmqZzWKO7XXz_y0_tg) Agent Loop 的核心运行时环境被称为 Pi（源自 @mariozechner/pi-agent-core[5]）

[qmd - mini cli search engine for your docs, knowledge bases, meeting notes, whatever](https://github.com/tobi/qmd)

[Inside OpenAI’s in-house data agent](https://openai.com/index/inside-our-in-house-data-agent/)

[The 80% Problem in Agentic Coding](https://addyo.substack.com/p/the-80-problem-in-agentic-coding) 1，车更快了，路却更堵了,2，早期采用者与众人之间的差距正在扩大，而非缩小。 3，新模式（声明式）：“这是需求。这是必须通过的测试。这是成功标准。你自己想办法。” 4，

[Automate Development Tasks with goose Headless Mode](https://block.github.io/goose/docs/tutorials/headless-goose/)

[The Rise of Coding Agent Orchestrators](https://www.aviator.co/blog/the-rise-of-coding-agent-orchestrators/)

[State of C++ 2026](https://devnewsletter.com/p/state-of-cpp-2026/)

[Nanobot: Ultra-Lightweight Alternative to OpenClaw](https://news.ycombinator.com/item?id=46897737)

[3天5k+星标，港大开源极致轻量OpenClaw, 1%代码量打造个人专属贾维斯](https://mp.weixin.qq.com/s/PMX4CESO6Edxy8rRT2LrLQ)

### Others

[]()

[]()

[From Pilot to Profit: Survey Reveals the Financial Services Industry Is Doubling Down on AI Investment and Open Source](https://blogs.nvidia.com/blog/ai-in-financial-services-survey-2026/?ncid=so-twit-861638-vt09)

[European Transparent IT JOB Market Report 2025](https://static.germantechjobs.de/market-reports/European-Transparent-IT-Job-Market-Report-2025.pdf)

[]()

[《康熙的红票》作者最新力作，讲述康熙朝储位之争的新故事｜豆瓣一周新书精选](https://mp.weixin.qq.com/s/Yrvdu9iLg-VvGlQqlq5gWg)

[Breaking Down the Shocking Ending of Fallout Season 2](https://time.com/7368810/fallout-season-2-ending-explained/) time没有paywall了

[美剧窝](https://www.meijuwo.cc/)

[]()

[新一代中性能图片查看器](https://pic.ghxi.com/)

[]()

[]()

[深度学习 本质上就是三步](https://chatgpt.com/share/697d4c40-c3cc-8009-9276-1ee10c88e495) 
```
把东西“翻译成数字” → 让机器试着算答案 → 根据算错的地方反过来改参数。

Encoding（编码）：把现实世界的东西变成机器能算的数字。Decoding（解码）：把机器算出来的数字再变回人能理解的结果。反向传播（Backpropagation）：发现算错了，从结果倒推，逐层修正内部参数。神经网络做的事情很朴素：一层一层做：加权求和 + 非线性变化。反向传播（Backpropagation）：错了怎么办？

先说“正向”，训练时流程是：输入 → Encoding → 网络计算 → 输出 → 和标准答案比。关键问题：到底是哪一层、哪个参数，导致我认错了？直接答案：不知道，只能从后往前一点点算。就是“反向传播”，反向传播 = 甩锅大会。

流程：先算“我错得有多离谱”（loss）,从最后一层开始问：“你对这个错误负多少责任？”，把责任一点点往前传。

每个参数：往“让错误变小”的方向微调一点点。一个极简比喻，你在练投篮：投偏了，你不会“全部推倒重来”，而是：手抬高一点，力气小一点。反向传播就是告诉你：哪个“动作”该怎么微调。

不管多复杂，最小深度学习程序一定包含这 5 个部分：1. 数据（Data）2. 编码（Encoding）3. 模型（Model）4. 损失函数（Loss）5. 反向更新（Backprop + Update）

for 每一次训练:
    x = encode(输入)
    y_pred = model(x)
    loss = compare(y_pred, y_true)
    根据 loss 反向调整 model 参数

最简单的损失函数：平方误差，loss = (预测值 - 正确值)^2

我们用一个“极简版反向传播”：
  w = w - 学习率 * 梯度
  b = b - 学习率 * 梯度

你现在不需要理解数学细节，只记住一句话：反向传播 = 算“该往哪个方向调参数，调多少”

把一切连起来（训练循环）
import random

# 生成训练数据
data = []
for _ in range(100):
    x = random.uniform(0, 10)
    y = 1 if x > 5 else 0   # 人工规则
    data.append((x, y))

def encode(x):
    return x

def model(x):
    return w * x + b

def decode(y):
    return 1 if y > 5 else 0

def loss_fn(y_pred, y_true):
    return (y_pred - y_true) ** 2

lr = 0.01  # 学习率

def backward(x, y_pred, y_true):
    global w, b
    grad = 2 * (y_pred - y_true)
    w -= lr * grad * x
    b -= lr * grad

for epoch in range(50):
    total_loss = 0

    for x, y in data:
        x_enc = encode(x)
        y_pred = model(x_enc)
        loss = loss_fn(y_pred, y)
        backward(x_enc, y_pred, y)
        total_loss += loss

    print(f"epoch {epoch}, loss {total_loss:.2f}")


那 PyTorch / TensorFlow 干了什么？一句话：帮你自动写了 backward()。

现实模型：参数成千上万，梯度人算不可能

PyTorch 的核心价值只有一个：
  loss.backward()
  optimizer.step()

你刚才“手搓”的逻辑，它帮你自动化了。


```

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()

[]()